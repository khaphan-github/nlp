{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d63f43",
   "metadata": {},
   "source": [
    "### Transformation-Based Learning (TBL) in Natural Language Processing (NLP). It is a rule-based machine learning algorithm,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12584c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /workspaces/py_env_research/.conda/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /workspaces/py_env_research/.conda/lib/python3.11/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /workspaces/py_env_research/.conda/lib/python3.11/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /workspaces/py_env_research/.conda/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /workspaces/py_env_research/.conda/lib/python3.11/site-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cb8c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define word banks by POS tag\n",
    "determiners = ['The', 'A', 'That', 'This', 'These']\n",
    "nouns = ['dog', 'cat', 'bird', 'car', 'robot', 'man', 'woman', 'child', 'apple']\n",
    "verbs = ['runs', 'jumps', 'sleeps', 'barks', 'drives', 'flies', 'eats', 'thinks']\n",
    "adjectives = ['big', 'small', 'happy', 'angry', 'blue', 'fast', 'quiet']\n",
    "\n",
    "# POS tag mappings\n",
    "pos_tags = {\n",
    "    'determiners': 'DT',\n",
    "    'nouns': 'NN',\n",
    "    'verbs': 'VB',\n",
    "    'adjectives': 'JJ'\n",
    "}\n",
    "\n",
    "# Sentence templates (sequence of POS roles)\n",
    "templates = [\n",
    "    ['determiners', 'nouns', 'verbs'],\n",
    "    ['determiners', 'adjectives', 'nouns', 'verbs'],\n",
    "    ['determiners', 'nouns', 'verbs', 'adverbs'],\n",
    "    ['determiners', 'nouns', 'verbs', 'determiners', 'nouns']\n",
    "]\n",
    "\n",
    "# Optional adverb list\n",
    "adverbs = ['quickly', 'loudly', 'quietly', 'suddenly']\n",
    "pos_tags['adverbs'] = 'RB'\n",
    "\n",
    "# Extend word bank for random selection\n",
    "word_bank = {\n",
    "    'determiners': determiners,\n",
    "    'nouns': nouns,\n",
    "    'verbs': verbs,\n",
    "    'adjectives': adjectives,\n",
    "    'adverbs': adverbs\n",
    "}\n",
    "\n",
    "# Function to generate a single sentence\n",
    "def generate_sentence(template):\n",
    "    sentence = []\n",
    "    for part in template:\n",
    "        word = random.choice(word_bank[part])\n",
    "        tag = pos_tags[part]\n",
    "        sentence.append((word, tag))\n",
    "    return sentence\n",
    "\n",
    "# Generate synthetic dataset\n",
    "def generate_dataset(n=100):\n",
    "    dataset = []\n",
    "    for _ in range(n):\n",
    "        template = random.choice(templates)\n",
    "        sentence = generate_sentence(template)\n",
    "        dataset.append(sentence)\n",
    "    return dataset\n",
    "\n",
    "# Example: Generate 100 synthetic training sentences\n",
    "synthetic_training_data = generate_dataset(1000)\n",
    "training_data = synthetic_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a0004b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "# Filter uniq\n",
    "def get_initial_tags(data):\n",
    "    word_tag_freq = defaultdict(Counter)\n",
    "    for sentence in data:\n",
    "        for word, tag in sentence:\n",
    "            word_tag_freq[word][tag] += 1\n",
    "\n",
    "    # Assign most frequent tag\n",
    "    most_freq_tag = {}\n",
    "    for word in word_tag_freq:\n",
    "        most_freq_tag[word] = word_tag_freq[word].most_common(1)[0][0]\n",
    "    return most_freq_tag\n",
    "\n",
    "\n",
    "def baseline_tag(sentence, tag_dict):\n",
    "    return [(word, tag_dict.get(word, 'NN')) for word, _ in sentence]  # default 'NN'\n",
    "  \n",
    "class Rule:\n",
    "    def __init__(self, from_tag, to_tag, prev_tag):\n",
    "        self.from_tag = from_tag\n",
    "        self.to_tag = to_tag\n",
    "        self.prev_tag = prev_tag\n",
    "\n",
    "    def apply(self, tagged_sentence):\n",
    "        new_sentence = tagged_sentence[:]\n",
    "        for i in range(1, len(tagged_sentence)):\n",
    "            _, prev_tag = new_sentence[i - 1]\n",
    "            word, tag = new_sentence[i]\n",
    "            if tag == self.from_tag and prev_tag == self.prev_tag:\n",
    "                new_sentence[i] = (word, self.to_tag)\n",
    "        return new_sentence\n",
    "      \n",
    "def evaluate(tagged, gold):\n",
    "    return sum(1 for (_, t1), (_, t2) in zip(tagged, gold) if t1 == t2)\n",
    "\n",
    "def learn_rules(training_data, tag_dict):\n",
    "    rules = []\n",
    "    for epoch in range(1000):  # number of iterations\n",
    "        best_rule = None\n",
    "        best_improvement = 0\n",
    "        for from_tag in ['NN', 'VB']:\n",
    "            for to_tag in ['NN', 'VB']:\n",
    "                if from_tag == to_tag:\n",
    "                    continue\n",
    "                for prev_tag in ['DT', 'NN', 'VB']:\n",
    "                    rule = Rule(from_tag, to_tag, prev_tag)\n",
    "                    improvement = 0\n",
    "                    for sent_idx, sentence in enumerate(training_data):\n",
    "                        gold = sentence\n",
    "                        pred = baseline_tag(sentence, tag_dict)\n",
    "                        pred = rule.apply(pred)\n",
    "                        improvement += evaluate(pred, gold) - evaluate(baseline_tag(sentence, tag_dict), gold)\n",
    "                    if improvement > best_improvement:\n",
    "                        best_improvement = improvement\n",
    "                        best_rule = rule\n",
    "        if best_rule:\n",
    "            rules.append(best_rule)\n",
    "            print(f\"Epoch {epoch + 1}: Learned rule - change {best_rule.from_tag} to {best_rule.to_tag} if prev tag is {best_rule.prev_tag}\")\n",
    "        else:\n",
    "            break\n",
    "    return rules\n",
    "\n",
    "def tag_with_rules(sentence, tag_dict, rules):\n",
    "    tagged = baseline_tag(sentence, tag_dict)\n",
    "    for rule in rules:\n",
    "        tagged = rule.apply(tagged)\n",
    "    return tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a012a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Tagged: [('The', 'DT'), ('cat', 'NN'), ('eat', 'NN'), ('woman', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "tag_dict = get_initial_tags(training_data)\n",
    "rules = learn_rules(training_data, tag_dict)\n",
    "print(rules)\n",
    "# Test on new sentence\n",
    "test_sentence = [('The', 'DT'), ('cat', 'NN'), ('eat', 'VB'), ('woman', 'NN')]\n",
    "predicted = tag_with_rules(test_sentence, tag_dict, rules)\n",
    "print(\"Tagged:\", predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
